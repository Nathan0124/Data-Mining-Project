{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np, scipy as sp,pandas as pd, matplotlib.pyplot as plt\n",
    "import matplotlib, sklearn\n",
    "import os,sys,csv\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "origin_headers = ['date_time', \n",
    "           'site_name',\n",
    "           'posa_continent',\n",
    "           'user_location_country',\n",
    "           'user_location_region',\n",
    "           'user_location_city',\n",
    "           'orig_destination_distance',\n",
    "           'user_id',\n",
    "           'is_mobile',\n",
    "           'is_package',\n",
    "           'channel',\n",
    "           'srch_ci',\n",
    "           'srch_co',\n",
    "           'srch_adults_cnt',\n",
    "           'srch_children_cnt',\n",
    "           'srch_rm_cnt',\n",
    "           'srch_destination_id',\n",
    "           'srch_destination_type_id',\n",
    "           'hotel_continent',\n",
    "           'hotel_country',\n",
    "           'hotel_market',\n",
    "           'is_booking',\n",
    "           'cnt',\n",
    "           'hotel_cluster']\n",
    "\n",
    "updated_headers = ['date_time',\n",
    "           'in_date',\n",
    "           'in_days',\n",
    "           'site_name',\n",
    "           'posa_continent',\n",
    "           'user_location_country',\n",
    "           'user_location_region',\n",
    "           'user_location_city',\n",
    "           'hotel_continent',\n",
    "           'hotel_country',\n",
    "           'hotel_market',\n",
    "           'srch_destination_id',\n",
    "           'orig_destination_distance',\n",
    "           'user_id',\n",
    "           'is_mobile',\n",
    "           'is_package',\n",
    "           'channel',\n",
    "           'srch_adults_cnt',\n",
    "           'srch_children_cnt',\n",
    "           'srch_rm_cnt',\n",
    "           'srch_destination_type_id',\n",
    "           'is_booking',\n",
    "           'cnt',\n",
    "           'hotel_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def uniqify(seq, idfun=None): \n",
    "    # order preserving\n",
    "    if idfun is None:\n",
    "        def idfun(x): return x\n",
    "    seen = {}\n",
    "    result = []\n",
    "    for item in seq:\n",
    "        marker = idfun(item)\n",
    "        if marker in seen: \n",
    "            continue\n",
    "        seen[marker] = 1\n",
    "        result.append(item)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geospatial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import cPickle as pk\n",
    "\n",
    "def geo_stat(fpath, isBooking = True):\n",
    "    fname, ext = os.path.splitext(fpath)\n",
    "    with open(fpath, \"r\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        header = reader.next()\n",
    "        book_item = header.index('is_booking')\n",
    "        destination_item = header.index('srch_destination_id')\n",
    "        country_item = header.index('hotel_country')\n",
    "        hotel_item = header.index('hotel_cluster')\n",
    "        \n",
    "        dest_map = {}\n",
    "        country_map = {}\n",
    "        \n",
    "        count = 0\n",
    "        for line in reader:\n",
    "            count += 1\n",
    "            if count%1000000 == 0:\n",
    "                print \"Processed:\", str(count)\n",
    "            \n",
    "            if isBooking and line[book_item] != '1':\n",
    "                continue\n",
    "                \n",
    "            destination_id = int(line[destination_item])\n",
    "            country_id = int(line[country_item])\n",
    "            hotel_cluster = int(line[hotel_item])\n",
    "            \n",
    "            value1 = dest_map.setdefault(destination_id, [])\n",
    "            value1.append(hotel_cluster)\n",
    "            \n",
    "            value2 = country_map.setdefault(country_id, [])\n",
    "            value2.append(hotel_cluster)          \n",
    "            \n",
    "    print 'IO Done. Now Processing...'\n",
    "    \n",
    "    for k, v in dest_map.iteritems():\n",
    "        v.sort(key=collections.Counter(v).get, reverse=True)\n",
    "        dest_map[k] = uniqify(v)\n",
    "    \n",
    "    for k, v in country_map.iteritems():\n",
    "        v.sort(key=collections.Counter(v).get, reverse=True)\n",
    "        country_map[k] = uniqify(v)\n",
    "        \n",
    "    print 'Done'\n",
    "    return dest_map, country_map\n",
    "\n",
    "\n",
    "def save_geo_stat(dstpath, dst_map, cntry_map):\n",
    "    with open(dstpath,'wb') as fp:\n",
    "        pk.dump(dst_map ,fp)\n",
    "        pk.dump(cntry_map,fp)\n",
    "        \n",
    "def load_geo_stat(srcpath):\n",
    "    with open(srcpath,'rb') as fp:\n",
    "        dst_map = pk.load(fp)\n",
    "        cntry_map = pk.load(fp)\n",
    "        return dst_map, cntry_map\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the list of hotel sorted by frequency in different destination region\n",
    "full_trainpath = '../data/train.csv'\n",
    "d_map, c_map = geo_stat(full_trainpath, False)\n",
    "save_geo_stat('../data/geo_stat_all.p', d_map, c_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def csv_map_by_key(srcpath, dstdir, key='hotel_country'):\n",
    "    if not os.path.exists(dstdir):\n",
    "        os.makedirs(dstdir)\n",
    "        \n",
    "    data = pd.read_csv(srcpath)\n",
    "    for name, group in data.groupby(key):\n",
    "        filepath = os.path.join(dstdir, str(name) + '.csv')\n",
    "        skipHeader = os.path.exists(filepath) \n",
    "        with open(filepath, \"a\") as csvfile:\n",
    "            group.to_csv(csvfile, mode='a', header=(not skipHeader))\n",
    "            \n",
    "def loop_map_by_key(dstdir):\n",
    "    #fname, ext = os.path.splitext(fpath)\n",
    "    for i in range(8):\n",
    "        print i\n",
    "        datapath = '../data/train_' + str(i) + '.csv'\n",
    "        csv_map_by_key(datapath, dstdir)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Map and save data according to country\n",
    "loop_map_by_key('../data/byCountry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling & Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import ml_metrics as mtr\n",
    "def map_5_scorer(estimator, X, y):\n",
    "    if X.shape[0] == 0:\n",
    "        return 1\n",
    "    prob = estimator.predict_proba(X)\n",
    "    labels = np.array(estimator.classes_)\n",
    "    \n",
    "    def top5(prob):\n",
    "        indice = sorted(range(len(prob)), key=lambda k: prob[k], reverse=True)\n",
    "        return labels[indice].tolist()\n",
    "    \n",
    "    y = map(lambda x:[x], y)\n",
    "    y_pred = np.apply_along_axis(top5, axis=1, arr=prob)\n",
    "    return mtr.mapk(y, y_pred, 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Recommend Most Popular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_freqRanking(datadir, isBooking = True):\n",
    "    dst_map, cntry_map = load_geo_stat('../data/geo_stat_booking.p')\n",
    "    \n",
    "    scores = []\n",
    "    freqs = []\n",
    "    for i in range(8):\n",
    "        \n",
    "        datapath = os.path.join( datadir, \"train_\" + str(i) + '.csv')\n",
    "        print i, datapath\n",
    "        if not os.path.exists(datapath):\n",
    "            continue\n",
    "        if not os.path.exists(datapath):\n",
    "            continue\n",
    "        \n",
    "        df = pd.read_csv(datapath)\n",
    "        \n",
    "        if isBooking:\n",
    "            df = df[df.is_booking == 1]\n",
    "        \n",
    "        for  dst, group in df.groupby('srch_destination_id'):\n",
    "            \n",
    "            y = group['hotel_cluster'].values.tolist()\n",
    "            y = map(lambda x:[x], y)\n",
    "            y_pred = [dst_map[dst][:5] for k in range(len(group))]\n",
    "            \n",
    "            assert(len(y) == len(y_pred))\n",
    "            \n",
    "            scores.append(mtr.mapk(y, y_pred, 5) )\n",
    "            freqs.append(len(group))\n",
    "            \n",
    "            print i, dst, scores[-1], freqs[-1]\n",
    "        \n",
    "    return np.average(scores, weights=freqs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print test_freqRanking('../data/', isBooking =True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cross_validation(df, feaTitles, split = 5, n_est = 10):\n",
    "    \n",
    "    X = df[feaTitles].as_matrix()\n",
    "    y = df.hotel_cluster.as_matrix()\n",
    "    \n",
    "    if X.shape[0] <= split*split:\n",
    "        return 1, 0\n",
    "        \n",
    "    if n_est == 0 or n_est == None:\n",
    "        n_est = len(feaTitles)\n",
    "    estimator = Pipeline([(\"imputer\", Imputer(missing_values=0,\n",
    "                                          strategy=\"median\",\n",
    "                                          axis=0)),\n",
    "                      (\"forest\", RandomForestClassifier(n_estimators=n_est,\n",
    "                                                       n_jobs=3))])\n",
    "    #from util import map_5_scorer\n",
    "    score = cross_val_score(estimator, X, y, cv=split, scoring=map_5_scorer)\n",
    "    return score.mean(), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_model(datadir, feaTitles, isBooking = False, split = 3, dstfile = None):\n",
    "    scores = []\n",
    "    freqs = []\n",
    "    \n",
    "    if dstfile!=None:\n",
    "        writer = csv.writer(open(dstfile, 'ab'))\n",
    "    else:\n",
    "        writer= None\n",
    "        \n",
    "    for i in range(213):\n",
    "        print i\n",
    "        datapath = os.path.join( datadir,str(i) + '.csv')\n",
    "        if not os.path.exists(datapath):\n",
    "            continue\n",
    "        \n",
    "        df = pd.read_csv(datapath)\n",
    "        \n",
    "        if isBooking:\n",
    "            df = df[df.is_booking == 1]        \n",
    "        \n",
    "        util.time_feature_processing(df, True)\n",
    "        util.nan_feature_processing(df,'orig_destination_distance')\n",
    "        \n",
    "        for  dst, group in df.groupby('srch_destination_id'):\n",
    "                \n",
    "                score, count = cross_validation(group, feaTitles, split)\n",
    "                scores.append(score)\n",
    "                freqs.append(count)\n",
    "                \n",
    "                print dst, score, count\n",
    "                if writer!= None:\n",
    "                    writer.writerow([str(i), str(dst), str(score), str(count)])\n",
    "                    \n",
    "    return np.average(scores, weights=freqs)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sample = pd.read_csv('../data/booking_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-40242751bd63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m            \u001b[1;34m'srch_rm_cnt'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m            'srch_destination_type_id']\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mtest_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/byCountry'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeaTitles\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfea_header\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0misBooking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-10-684c96b5f813>\u001b[0m in \u001b[0;36mtest_model\u001b[1;34m(datadir, feaTitles, isBooking, split, dstfile)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_booking\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime_feature_processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan_feature_processing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'orig_destination_distance'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/media/nianzu/Application/Files/Learning/Northwestern/EECS510-Social_Media_Mining/project/code/util.pyc\u001b[0m in \u001b[0;36mtime_feature_processing\u001b[1;34m(df, drop)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'in_days'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_interval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'in_date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_midpoint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'date_time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_dayofyear\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/nianzu/miniconda2/envs/work/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[0;32m   4059\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4060\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4061\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4062\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4063\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/nianzu/miniconda2/envs/work/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_apply_standard\u001b[1;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[0;32m   4115\u001b[0m                     \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_agg_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4116\u001b[0m                     result = lib.reduce(values, func, axis=axis, dummy=dummy,\n\u001b[1;32m-> 4117\u001b[1;33m                                         labels=labels)\n\u001b[0m\u001b[0;32m   4118\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4119\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/src/reduce.pyx\u001b[0m in \u001b[0;36mpandas.lib.reduce (pandas/lib.c:43539)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/src/reduce.pyx\u001b[0m in \u001b[0;36mpandas.lib.Reducer.get_result (pandas/lib.c:33736)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/media/nianzu/Application/Files/Learning/Northwestern/EECS510-Social_Media_Mining/project/code/util.pyc\u001b[0m in \u001b[0;36mtime_midpoint\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtime_midpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'srch_ci'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'srch_co'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPeriod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'srch_ci'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfreq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'D'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/nianzu/miniconda2/envs/work/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/nianzu/miniconda2/envs/work/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   1972\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1973\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1974\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1975\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1976\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/lib.pyx\u001b[0m in \u001b[0;36mpandas.lib.values_from_object (pandas/lib.c:4435)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m/home/nianzu/miniconda2/envs/work/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mget_values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;34m\"\"\" same as values (but handles sparseness conversions); is a view \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/nianzu/miniconda2/envs/work/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget_values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   3914\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3915\u001b[0m         \u001b[1;34m\"\"\" return a dense type view \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3916\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_block\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3917\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3918\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/nianzu/miniconda2/envs/work/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mto_dense\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mto_object_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmgr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fea_header = ['date_time',\n",
    "           'in_date',\n",
    "           'in_days',\n",
    "           'site_name',\n",
    "           'posa_continent',\n",
    "           'user_location_country',\n",
    "           'user_location_region',\n",
    "           'user_location_city',\n",
    "           'orig_destination_distance',\n",
    "           'user_id',\n",
    "           'is_mobile',\n",
    "           'is_package',\n",
    "           'channel',\n",
    "           'srch_adults_cnt',\n",
    "           'srch_children_cnt',\n",
    "           'srch_rm_cnt',\n",
    "           'srch_destination_type_id']\n",
    "test_model('../data/byCountry', feaTitles=fea_header,isBooking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/byCountry/113.csv')\n",
    "util.nan_feature_processing(df, 'orig_destination_distance')\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = sample.groupby('srch_destination_id')\n",
    "g.get_group(31682)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = list(range(0,10,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.array(x)\n",
    "x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rand_sample(df, ratio=0.3):\n",
    "    msk = np.random.rand(len(df)) < ratio\n",
    "    return df[msk], df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_data(datadir, lst, traindir, testfile, sr = 0.2):\n",
    "    \n",
    "    for i in lst:\n",
    "        print i\n",
    "        datapath = os.path.join( datadir,str(i) + '.csv')\n",
    "        if not os.path.exists(datapath):\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        df = pd.read_csv(datapath)\n",
    "        print len(df),\n",
    "        booking = df[df.is_booking == 1] \n",
    "        test, booking = rand_sample(booking, ratio=sr)\n",
    "        df = pd.concat([booking, df[df.is_booking!=1]])\n",
    "        print len(test), len(df)\n",
    "        \n",
    "        skipHeader = os.path.exists(testfile) \n",
    "        with open(testfile, \"a\") as csvfile:\n",
    "            test.to_csv(csvfile, mode='a', header=(not skipHeader))\n",
    "            \n",
    "        trainpath = os.path.join(traindir,str(i) + '.csv')\n",
    "        with open(trainpath, \"w\") as csvfile:\n",
    "            df.to_csv(csvfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4839 103 4736\n",
      "3\n",
      "7817 141 7676\n",
      "4\n",
      "11610 267 11343\n",
      "5\n",
      "325064 2748 322316\n",
      "6\n",
      "497 19 478\n",
      "7\n",
      "90774 1610 89164\n",
      "8\n",
      "1914010 16123 1897887\n",
      "9\n",
      "7687 123 7564\n",
      "10\n",
      "1812 12 1800\n",
      "11\n",
      "38289 1005 37284\n",
      "12\n",
      "47530 766 46764\n",
      "13\n",
      "72083 1237 70846\n",
      "14\n",
      "1539 15 1524\n",
      "15\n",
      "65654 1376 64278\n",
      "16\n",
      "206 2 204\n",
      "17\n",
      "73605 1304 72301\n",
      "18\n",
      "922 25 897\n",
      "19\n",
      "2275 63 2212\n",
      "20\n",
      "5502 119 5383\n",
      "21\n",
      "81445 1729 79716\n",
      "22\n",
      "273081 3291 269790\n",
      "23\n",
      "1767 32 1735\n",
      "24\n",
      "2235 59 2176\n",
      "25\n",
      "19478 459 19019\n",
      "26\n",
      "13877 63 13814\n",
      "27\n",
      "2938 66 2872\n",
      "28\n",
      "1852 33 1819\n",
      "29\n",
      "1089 16 1073\n",
      "30\n",
      "524 11 513\n",
      "31\n",
      "135237 2533 132704\n",
      "32\n",
      "58406 388 58018\n",
      "33\n",
      "265 9 256\n",
      "34\n",
      "138754 2869 135885\n",
      "35\n",
      "16338 100 16238\n",
      "36\n",
      "18076 190 17886\n",
      "37\n",
      "263 7 256\n",
      "38\n",
      "2939 88 2851\n",
      "39\n",
      "588 17 571\n",
      "40\n",
      "50 0 50\n",
      "41\n",
      "27 0 27\n",
      "42\n",
      "4719 51 4668\n",
      "43\n",
      "1383 40 1343\n",
      "44\n",
      "2751 34 2717\n",
      "45\n",
      "25413 536 24877\n",
      "46\n",
      "144343 3071 141272\n",
      "47\n",
      "210009 1198 208811\n",
      "48\n",
      "374351 4537 369814\n",
      "49\n",
      "100 1 99\n"
     ]
    }
   ],
   "source": [
    "split_data('../data/byCountry', [50], '../data/byCountry/train', '../data/byCountry/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def built_model(datadir, feaTitles, isBooking = False, sr = 0.2, dstfile = None):\n",
    "    scores = []\n",
    "    freqs = []\n",
    "    \n",
    "    \n",
    "    for i in range(213):\n",
    "        print i\n",
    "        datapath = os.path.join( datadir,str(i) + '.csv')\n",
    "        if not os.path.exists(datapath):\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        df = pd.read_csv(datapath)\n",
    "        booking = df[df.is_booking == 1] \n",
    "        if sr > 0:\n",
    "            test, booking = \n",
    "        if dstfile!=None:\n",
    "            skipHeader = os.path.exists(dstfile) \n",
    "            with open(filepath, \"a\") as csvfile:\n",
    "                group.to_csv(csvfile, mode='a', header=(not skipHeader))\n",
    "        \n",
    "        if isBooking:\n",
    "            df = df[df.is_booking == 1]        \n",
    "        \n",
    "        util.time_feature_processing(df, True)\n",
    "        util.nan_feature_processing(df,'orig_destination_distance')\n",
    "        \n",
    "        for  dst, group in df.groupby('srch_destination_id'):\n",
    "                \n",
    "                score, count = cross_validation(group, feaTitles, split)\n",
    "                scores.append(score)\n",
    "                freqs.append(count)\n",
    "                \n",
    "                print dst, score, count\n",
    "                if writer!= None:\n",
    "                    writer.writerow([str(i), str(dst), str(score), str(count)])\n",
    "                    \n",
    "    return np.average(scores, weights=freqs)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
